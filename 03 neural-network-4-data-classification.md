- [x]  üõ´ 2023-11-15 ‚úÖ 2023-11-22

---

## Zadanie √∫lohy (d) Probl√©m 3. Klasifik√°cia datasetov scikit-learn

Nasej √∫lohou bolo vytvori≈• sofistikovan√∫ neur√≥nov√∫ sie≈•, ktor√° bude schopn√° klasifikova≈• d√°ta zo zn√°meho datasetu
dostupn√©ho v kni≈ænici scikit-learn.

## Implementaƒçn√© prostredie

Program je vytvorenej v `Python 3.10.11` a na spr√°vne fungovanie sa vyu≈æ√≠va nasleduj√∫ci kni≈ænici:

- `argparse`
- `tensorflow`
- `sklearn`
- `matplotlib.pyplot`
- `seaborn`

### Vyber datasetu

Vybral som `make_blobs` dataset z kni≈ænice `sklearn` a vytvoril som 3 architekt√∫ry neur√≥nov√Ωch siet√≠.

V√Ωber tohto s√∫boru √∫dajov vych√°dza z niekoƒæk√Ωch kƒæ√∫ƒçov√Ωch d√¥vodov:

- Kontext √∫lohy:
    - Tento s√∫bor √∫dajov modeluje vlastnosti buniek, ktor√© charakterizuj√∫ rakovinu prsn√≠ka. Rakovina prsn√≠ka je
      jedn√Ωm z najƒçastej≈°√≠ch typov rakoviny u ≈æien a jej vƒçasn√© odhalenie zohr√°va kƒæ√∫ƒçov√∫ √∫lohu pri lieƒçbe a pre≈æ√≠van√≠
      pacientov.
- Bin√°rna klasifik√°cia:
    - Dataset poskytuje mo≈ænos≈• vykona≈• bin√°rnu klasifik√°ciu (ben√≠gny alebo mal√≠gny n√°dor), ƒço umo≈æ≈àuje
      vytvori≈• model na urƒçenie povahy n√°doru na z√°klade jeho vlastnost√≠.
- Dobre definovan√© charakteristiky:
    - S√∫bor √∫dajov obsahuje dobre definovan√© charakteristiky buniek, ako je polomer,
      text√∫ra, obvod, plocha a ƒèal≈°ie parametre, ktor√© m√¥≈æu by≈• d√¥le≈æit√© pri urƒçovan√≠ typu n√°doru.
- V√Ωskumn√Ω z√°ujem:
    - Anal√Ωza a vytv√°ranie modelov na takomto s√∫bore √∫dajov umo≈æ≈àuje hlb≈°ie pochopi≈•, ktor√© bunkov√©
      charakteristiky m√¥≈æu s√∫visie≈• s t√Ωm, ƒçi je n√°dor mal√≠gny alebo ben√≠gny.

## Priebeh programu

Program sa spust√≠, a pomocou oper√°tora ‚Äû--architecture‚Äú je mozne nastavi≈• architecture neurnovej siete:

```cmd
use:
   python main.py [--architecture <1-3>](1)
```

Program bude vypisova≈• aktu√°lni hodnoty, ako:

- Aktu√°lnu epochu (strata, presnos≈• pre kazdy epoch)
- A report √°≈æ na konci

A po, ukonƒçeniu zobraz√≠ metriky, aj graficky:

```
Classification Report:
              precision    recall  f1-score   support

           0       1.00      1.00      1.00       103
           1       1.00      1.00      1.00        97

    accuracy                           1.00       200
   macro avg       1.00      1.00      1.00       200
weighted avg       1.00      1.00      1.00       200
```

<div style="display: grid; grid-template-columns: repeat(3, minmax(0, 1fr));">

![accuracy.png](accuracy.png)

![loss.png](loss.png)

![confusion_matrix.png](confusion_matrix.png)

</div>

- Presnos≈• testu:
    - Vypoƒç√≠ta sa pre ka≈æd√∫ architekt√∫ru po vy≈°kolen√≠ a vyhodnoten√≠ na testovacej mno≈æine.
- Spr√°va o klasifik√°cii:
    - Uv√°dza presnos≈•, odvolanie, sk√≥re F1 a podporu pre obe triedy.
- Matica zm√§toƒçnosti:
    - Visualize pravdiv√© pozit√≠vne, falo≈°ne pozit√≠vne, pravdiv√© negat√≠vne a falo≈°ne negat√≠vne
      predpovede modelu.

## Architekt√∫ry

### Prv√°

- Dve skryt√© vrstvy
    - Vrstva 1: 128 neur√≥nov, ReLU aktiv√°cia, 30% v√Ωpadok
    - Vrstva 2: 64 neur√≥nov, aktiv√°cia ReLU, 30 % v√Ωpadok
- V√Ωstupn√° vrstva: 1 neur√≥n, Sigmoid aktiv√°cia (pre bin√°rnu klasifik√°ciu)

T√°to architekt√∫ra m√° menej vrstiev a neur√≥nov, ƒço m√¥≈æe vies≈• k nedostatoƒçn√©mu nauƒçeniu modelu. M√° tendenciu k
jednoduch≈°√≠m modelom a nemus√≠ by≈• schopn√° zvl√°dnu≈• uƒçenie zlo≈æit√Ωch vz≈•ahov v √∫dajoch. M√¥≈æe v≈°ak ma≈• tendenciu
stabilnej≈°ie zov≈°eobec≈àova≈• nov√© √∫daje, ƒç√≠m sa vyhne nadmern√©mu uƒçeniu.

```python
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, input_shape=(X_train.shape[1],), activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
```

### Druha

- Tri skryt√© vrstvy
    - Vrstva 1: 256 neur√≥nov s line√°rnou aktiv√°ciou a 40% v√Ωpadkom
    - Vrstva 2: 128 neur√≥nov s line√°rnou aktiv√°ciou a 40 % v√Ωpadkom
    - Vrstva 3: 64 neur√≥nov s line√°rnou aktiv√°ciou a 40 % v√Ωpadkom
- V√Ωstupn√° vrstva: Zachovan√Ω jeden neur√≥n so sigmoid aktivaƒçnou funkciou.

Pou≈æitie line√°rnej aktiv√°cie vo v≈°etk√Ωch skryt√Ωch vrstv√°ch m√¥≈æe obmedzi≈• schopnos≈• modelu z√≠ska≈• komplexn√© neline√°rne
z√°vislosti v √∫dajoch. To m√¥≈æe vies≈• k strate schopnosti zov≈°eobec≈àovania a zhor≈°eniu v√Ωkonnosti modelu na nov√Ωch
√∫dajoch.

```python
model = tf.keras.Sequential([
    tf.keras.layers.Dense(256, input_shape=(X_train.shape[1],), activation='linear'),
    tf.keras.layers.Dropout(0.4),
    tf.keras.layers.Dense(128, activation='linear'),
    tf.keras.layers.Dropout(0.4),
    tf.keras.layers.Dense(64, activation='linear'),
    tf.keras.layers.Dropout(0.4),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
```

### Tretia

- Tri skryt√© vrstvy
    - Vrstva 1: 64 neur√≥nov, ReLU aktiv√°cia, 20% v√Ωpadok
    - Vrstva 2: 128 neur√≥nov, ReLU aktiv√°cia, 30 % v√Ωpadok
    - Vrstva 3: 256 neur√≥nov, ReLU aktiv√°cia, 30% v√Ωpadok
- V√Ωstupn√° vrstva: 1 neur√≥n, Sigmoid aktiv√°cia (pre bin√°rnu klasifik√°ciu)

T√°to architekt√∫ra predstavuje zlo≈æitej≈°√≠ model s r√¥znymi kombin√°ciami vrstiev, aktivaƒçn√Ωch funkci√≠ a vypad√°vania. Tak√©to
siete maj√∫ v√§ƒç≈°√≠ potenci√°l nauƒçi≈• sa zlo≈æitej≈°ie z√°vislosti v √∫dajoch, ale m√¥≈æu trpie≈• nadmern√Ωm uƒçen√≠m na tr√©novan√Ωch
√∫dajoch.

```python
model = tf.keras.Sequential([
    tf.keras.layers.Dense(64, input_shape=(X_train.shape[1],), activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
```

---

Tieto architekt√∫ry sa l√≠≈°ia poƒçtom skryt√Ωch vrstiev, poƒçtom neur√≥nov v ka≈ædej vrstve, pou≈æit√Ωmi aktivaƒçn√Ωmi funkciami
(ReLU, sigmoid, linear) a mierou vypad√∫vania pou≈æitou na regulariz√°ciu.

## Pomer testovac√≠ch a ≈°koliacich √∫dajov

Na rozdelenie s√∫boru √∫dajov na tr√©ningov√∫ a testovaciu mno≈æinu bol zvolen√Ω pomer `80:20`:

```python
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)
```

Tento pomer zabezpeƒçuje v√Ωznamn√∫ ƒças≈• √∫dajov na tr√©novanie modelu a z√°rove≈à zachov√°va znaƒçn√Ω samostatn√Ω s√∫bor na
vyhodnotenie v√Ωkonnosti modelu. Pom√°ha predch√°dza≈• nadmern√©mu prisp√¥sobeniu t√Ωm, ≈æe poskytuje dostatok √∫dajov na
zov≈°eobecnenie.

![running_program.gif](running_program.gif)